# é‡è¿”ç§˜å¢ƒ
## Debugä¿¡æ¯
è·ç¦»ç›¸å…³ä¿¡æ¯: çŽ¯å¢ƒä¸­ç¦»æ•£åŒ–ç½‘æ ¼å¤§å°ä¸º `128x128`, æ¯ä¸ªç½‘æ ¼è¢«ç»†åˆ†ä¸º `500` ç è·ç¦», å› æ­¤æ€»ç½‘æ ¼å¤§å°ä¸º `64000x64000`
1. æ¯æ­¥ç§»åŠ¨çš„è·ç¦», æ²¡æœ‰ç§»é€ŸåŠ æˆçš„æƒ…å†µä¸‹ 660~711, æœ‰ç§»é€Ÿbuffçš„æƒ…å†µä¸‹ 900~1100, é—ªçŽ°ç§»åŠ¨è·ç¦» 7900~8100, é€šè¿‡è¿™äº›å¯ä»¥åˆ¤æ–­æ˜¯å¦æ’žå¢™, ä»£ç ä¸­å¤„äºŽ `diy.feature.constants.py` æ–‡ä»¶ä¸‹.
2. æ¨¡åž‹çš„obsè¾“å‡ºçš„mapæ˜¯æœ‰ä¸Šä¸‹ç¿»è½¬çš„.
3. buffçš„ä½¿ç”¨æ—¶é•¿æ˜¯50æ­¥, æ¡åˆ°ä¹‹åŽä¸å†ä¼šåˆ·æ–°æ–°çš„buffäº†.
4. é—ªçŽ°çš„cdä¸º600æ­¥, ä¸€ä¸ªepisodeæœ€å¤§åŸºæœ¬ä¸º550æ­¥, å› æ­¤åŸºæœ¬ä¸ä¼šä½¿ç”¨åˆ°ä¸¤æ¬¡é—ªçŽ°çš„.
5. `env.step` è¿”å›žçš„ `score` æ˜¯ä¸€ä¸ªç±», è€Œä¸æ˜¯ä¸€ä¸ª `int`, é€šè¿‡ `score.score` èŽ·å¾—åˆ°çš„å¾—åˆ†æ˜¯å½“å‰æ€»å®ç®±çš„å¾—åˆ†.
### obsä¿¡æ¯è§£åŒ…
åˆ†åˆ«å¯¹ `obs` å’Œ `info` è¿›è¡Œè§£åŒ…, åŒ…ä¸­åŒ…å«çš„å±žæ€§å¯ä»¥åœ¨å®˜ç½‘ [æ•°æ®åè®®](https://doc.aiarena.tencent.com/competition/back_to_the_realm/1.0.0/guidebook/protocol/) ä¸­æŸ¥åˆ°, ä»£ç ä¸­è§ `diy.feature.definition.py` ä¸­çš„ `obs2dict, info2dict` å‡½æ•°.
### ç½‘ç»œç»“æž„è®¾è®¡
ä»£ç è¯·è§ `diy.algorithm.model.py` ä¸­çš„ `Model` ç±», å¯¹äºŽ `actor, critic` æˆ‘ä»¬åˆ†åˆ«ä½¿ç”¨äº†ä¸¤ä¸ª backbone (å¯ä»¥æµ‹è¯•å…±äº« backbone):
- å·ç§¯ä»…ä½¿ç”¨çš„æ˜¯æœ€æœ´ç´ çš„3å±‚CNN+ReLU, å›¾åƒè¾“å…¥ç»´åº¦ä¸º `(4, 51, 51)`, å°±æ˜¯ `obs` ä¸­è¿”å›žçš„å›¾åƒå †å è€Œæˆ.
- çŠ¶æ€è¾“å…¥, ç»´åº¦ä¸º `(31,)`: Agentå½’ä¸€åŒ–åŽçš„ä½ç½® `(2,)`, å®ç®±çš„å­˜åœ¨æ ‡å¿— `(13,)`, å®ç®±grid_distance `(13,)`, buffå­˜åœ¨æ ‡å¿— `(1,)`, buffçš„grid_distance `(1,)`, ç»ˆç‚¹çš„grid_distance `(1,)`.
åŠ¨ä½œç©ºé—´ä¸º `(16,)`, å‰8ç»´åº¦ä¸ºæ­£å¸¸ç§»åŠ¨, åŽ8ç»´åº¦ä¸ºä½¿ç”¨é—ªçŽ°çš„ç§»åŠ¨, ç§»åŠ¨éƒ½æ˜¯8ä¸ªæ–¹å‘.
## Distribution PPO
åœ¨ä¸€é™¢è¿™è¾¹ä»Ž8æœˆ2æ—¥å¼€å§‹å­¦ä¹ æºç  (æºç å­¦ä¹ è¯·è§ [ä»£ç é€»è¾‘](../../assets/code_logic.md)), ç›´åˆ°8æœˆ11æ—¥å®Œæˆåˆ†å¸ƒå¼PPOä»£ç , ä¸»è¦æ³¨æ„å¦‚ä¸‹å†…å®¹:
1. replay bufferçš„sampleæ¨¡å¼è°ƒè¯•, æœ€ç»ˆè¿˜æ˜¯é€‰æ‹© `Uniform` æ¨¡åž‹
2. bufferä¸­çš„æ¯æ¡ä¿¡æ¯æ˜¯ä¸€ä¸ªè¿žç»­çš„è½¨è¿¹ä¿¡æ¯ (s, a, r, done, last_s, last_done), è¿™6ä¸ªä¿¡æ¯, è½¨è¿¹é•¿åº¦è®¾ç½®ä¸º `num_steps`, åœ¨learnerä¸­é€šè¿‡ GAE ä¼˜åŠ¿å‡½æ•°, ç”¨ç­–ç•¥ç½‘ç»œè®¡ç®— `logprob`
3. `agent` ä¸­ä¸èƒ½å­˜å‚¨çŽ¯å¢ƒ, ä¹Ÿå°±æ˜¯ä¸èƒ½æŠŠ `rollout` å‡½æ•°æ”¾åˆ° `agent` ç±»ä¸­, å› ä¸ºæ‰€æœ‰çš„ `aisrv` æ˜¯å…±äº«åŒä¸€ä¸ª `agent`, æˆ‘ä»¬åªèƒ½é€šè¿‡ `predict` å‡½æ•°åŽ»åšåŠ¨ä½œé¢„æµ‹ (è¿™ä¹Ÿæ˜¯ä¸€ä¸ªé€šè®¯è¿‡ç¨‹), æ‰€ä»¥ `agent` å’ŒçŽ¯å¢ƒäº¤äº’çš„è¿‡ç¨‹å…¨éƒ¨è¦åœ¨ `workflow` ä¸­å®Œæˆ.
4. æ¨¡åž‹åŒæ­¥ç»†èŠ‚, ç”±äºŽPPOè¦æ±‚æ¨¡åž‹çš„é«˜åŒæ­¥æ€§, å› æ­¤æˆ‘å°†æ¨¡åž‹çš„è‡ªåŠ¨ä¿å­˜æ¬¡æ•°è®¾ç½®ä¸º `dump_model_freq=2`, æ¨¡åž‹æƒé‡æ–‡ä»¶åŒæ­¥æ—¶é—´è®¾ç½®ä¸º `model_file_sync_per_minutes=1` (è¿™é‡Œæœ€å°å•ä½å°±æ˜¯åˆ†é’Ÿ, æœ€å°å°±æ˜¯1åˆ†é’Ÿ)
5. æ¨¡åž‹ä¿å­˜: å…·ä½“ä¿å­˜ç»†èŠ‚å‚è§ [ä»£ç é€»è¾‘ - save_modelé€»è¾‘](../../assets/code_logic.md#save_modelé€»è¾‘), ç®€å•å°±æ˜¯, ç”±äºŽ `learner` å’Œ `actor` ä¹‹é—´çš„æ¨¡åž‹æœ‰å»¶è¿Ÿ, å› æ­¤ä¸­é—´æœ‰ä¸ªæ¨¡åž‹æ± ä¸“é—¨ç”¨æ¥åŒæ­¥ `learner` ä¸­çš„æœ€æ–°æ¨¡åž‹, è€Œæ¨¡åž‹æ± çš„æ¨¡åž‹åŒæ­¥åªä¼šä»Žå‘¨æœŸæ€§è‡ªåŠ¨ä¿å­˜çš„æ¨¡åž‹ä¸­è¿›è¡ŒèŽ·å– (ä¹Ÿå°±æ˜¯ `dump_model_freq` è®¾ç½®çš„å‘¨æœŸ), æ³¨æ„è¿™ä¸ªä¿å­˜çš„æ¨¡åž‹ä¸ä¼šä¿å­˜åœ¨æœ¬åœ°. è€Œæˆ‘ä»¬çš„æ‰‹åŠ¨è°ƒç”¨ `agent.save_model()` å‡½æ•°, æ¨¡åž‹æ‰ä¼šä¿å­˜åœ¨æœ¬åœ°, è€Œè¿™ä¸ªä¿å­˜æœ‰ä¸ªæœ€å¤§é™åˆ¶æ¬¡æ•° `200`, æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¾ç½® `user_save_mode_max_count = 0` å°±æ˜¯æ— é™åˆ¶ä¿å­˜æ¬¡æ•°, ä¸ºäº†é¿å…ç©ºé—´çˆ†ç‚¸, åœ¨ä¿å­˜æ¨¡åž‹åŽ, æ‰§è¡Œä»¥ä¸‹å‡½æ•°åˆ æŽ‰ä¹‹å‰æ—§çš„æ¨¡åž‹èŠ‚çœç©ºé—´ (é»˜è®¤ä¿å­˜æœ€è¿‘çš„10ä¸ªèŠ‚ç‚¹, ä½¿ç”¨æ—¶åªéœ€å°† `logger` ä¼ å…¥å³å¯æ‰“å°æ—¥å¿—):
```python
from pathlib import Path
from kaiwudrl.common.config.config_control import CONFIG

def clean_ckpt_memory(min_num_model=10, logger=None):
  """
  Remove old checkpoints generate by autosave (save frequency=CONFIG.dump_model_freq),
  you can find autosave code at
  `kaiwudrl.common.algorithms.standard_model_wrapper_pytorch.StandardModelWrapperPytorch.after_train()`

  Usage: Call this function in `agent.learn(...)` or `train_workflow.workflow`, 
  recommend in `agent.learn(...)` since it is a single process,
  add small delay as you like~~~
  """
  path_tmp_dir = Path(f"{CONFIG.restore_dir}/{CONFIG.app}_{CONFIG.algo}/")
  files = sorted(list(path_tmp_dir.glob('model.ckpt-*')), key=lambda x: int(str(x).rsplit('.', 1)[0].rsplit('-', 1)[1]))
  if len(files) > min_num_model:
    info = f"Remove old ckpts ({path_tmp_dir}): "
    for p in files[:-min_num_model]:  # just keep latest checkpoint
      p.unlink()
      info += f"{p.stem} "
    if logger is not None:
      logger.info(info)
```
### è®­ç»ƒé…ç½®ç»†èŠ‚
PPOçš„é‡è¦å‚æ•°åŒ…å«ä»¥ä¸‹å‡ ä¸ª, æˆ‘è¿™ä»¥8è¿›ç¨‹å¯åŠ¨ä¸ºä¾‹:
```toml
# å…³é—­æ­»å¾ªçŽ¯è®­ç»ƒ, è€Œæ˜¯åŸºäºŽæœ‰å¤šå°‘æ–°åŠ å…¥çš„æ ·æœ¬æ•°ç›®å¼€å§‹è®­ç»ƒ
learner_train_by_while_true = false
# é»˜è®¤å°±æ˜¯ off-policy, å½“å‰ä¹Ÿä¸æ”¯æŒ on-policy, 
# è¿™ä¸ªä¸»è¦å½±å“bufferå¯åŠ¨è®­ç»ƒçš„æ¬¡æ•°
algorithm_on_policy_or_off_policy = 'off-policy'
# bufferçš„å¤§å°, è¿™ä¸ªå’Œå®¢æˆ·ç«¯å¯åŠ¨çš„è¿›ç¨‹æ•°ç›¸å…³, 
# å¦‚æžœæ˜¯é‡‡æ ·æ¨¡åž‹æ˜¯Uniformæœ€å¥½æ˜¯è¿›ç¨‹æ•°*2~4, 
# å¦‚æžœæ˜¯Fifoé‚£ä¹ˆå†™è¿›ç¨‹æ•°å°±è¡Œ, å› ä¸ºæ¯æ¬¡å°±å–çš„æ˜¯æœ€åŽä¸€ä¸ª
replay_buffer_capacity = 24
# å½“bufferä¸­å­˜åœ¨replay_buffer_cAapacity/preload_ratioä¸ªæ ·æœ¬æ—¶,
# å¼€å§‹è®­ç»ƒ, æˆ‘é…ç½®å¡žæ»¡äº†å°±å¼€å§‹è®­
preload_ratio = 1  
# learnerä¸­æ¯æ¬¡å‘agent.learnä¼ å…¥çš„æ ·æœ¬æ•°ç›®, 
# Uniformæ¨¡å¼å»ºè®®å°±æ˜¯è¿›ç¨‹æ•°, Fifoæ¨¡åž‹åªèƒ½å†™1, å› ä¸ºä»–åªä¼šå–æœ€åŽä¸€ä¸ª
train_batch_size = 8
# æ ·æœ¬æ¶ˆè€—/ç”Ÿæˆé‡‡æ ·æ¯”
# å’Œofflineçš„è®­ç»ƒæ¬¡æ•°æœ‰å…³, å½“ä¸Šæ¬¡è®­ç»ƒåŽæ–°åŠ è¿›æ¥çš„æ ·æœ¬æ•°ç›®è¶…è¿‡
# train_batch_size / production_consume_ratioæ—¶å€™å†å¼€å§‹ä¸€æ¬¡è®­ç»ƒ
production_consume_ratio = 1
# é‡‡æ ·ç­–ç•¥é€‰æ‹©
# Fifoåªä¼šé€‰å–æœ€åŽä¸€ä¸ªæ ·æœ¬, å¯¼è‡´æ•´ä¸ªbatché‡Œé¢å…¨æ˜¯ä¸€æ ·çš„, åªæœ‰åœ¨train_batch_size=1æœ‰ç”¨
# æŽ¨èUniformå‡åŒ€é‡‡æ ·
reverb_sampler = "reverb.selectors.Uniform"
# è®­ç»ƒé—´éš”å¤šå°‘æ­¥è¾“å‡ºmodelæ–‡ä»¶, è¿™ä¸ªå°±æ˜¯å¯ä»¥åŒæ­¥åˆ°æ¨¡åž‹æ± çš„è‡ªåŠ¨ä¿å­˜é¢‘çŽ‡
dump_model_freq = 2
```

## 2024.8.12.
### v0.4
å›ºå®šèµ·ç‚¹2ç»ˆç‚¹1, å®ç®±æ•°ç›®ä¸º[13, 'norm', 13, 'norm'], è®­ç»ƒ1e7æ­¥, åŒæ ·ä¹Ÿé‡åˆ°äº†è®­ç»ƒä¸€æ®µæ—¶é—´åŽ, valueç›´æŽ¥å´©æºƒçš„é—®é¢˜.
### v0.4.1
è®¨è®ºåŽè€ƒè™‘æœ‰å¦‚ä¸‹è¿™äº›æ”¹è¿›æ–¹å‘, é€æ­¥è¿›è¡Œå°è¯•, çœ‹èƒ½å¦è§£å†³é—®é¢˜:

- [x] returnè¿‡å¤§, å°è¯•ç›´æŽ¥ /10 è¿›è¡Œç¼©æ”¾
- [x] logprob åº”è¯¥æ˜¯ç”±actorç»™å‡ºä¼ åˆ°bufferé‡Œé¢, è€Œéžé€šè¿‡learneré‡æ–°è®¡ç®—
- [ ] value æ˜¯å¦åº”è¯¥ä¹Ÿæ˜¯ç”±actorç»™å‡º
- [x] å¢žå¤§`buffer size`åˆ°`è¿›ç¨‹æ•°*10`, å¢žå¤§`batchsize`åˆ°è¿›ç¨‹æ•°*3, å¢žå¤§æ¶ˆè€—/ç”Ÿæˆæ¯”`production_consume_ratio=3`, é¢„åŠ è½½æ¯”ä¾‹ `preload_ratio=2`
- [x] æ—¥å¿—ä¸­è¾“å‡ºclipåŽçš„`grad_norm`æŸ¥çœ‹æ˜¯å¦ä¼šé¡¶æ»¡`max_grad_norm`
- [x] å‡å°å­¦ä¹ çŽ‡ `2.5e-4 -> 5e-5`

## 2024.8.13.
### v0.4.2
1. ä¿®å¤é—ªçŽ°æ’žå¢™çš„é”™è¯¯å¥–åŠ±
2. envä¸­è®¡ç®—ratioæ—¶å¿˜è®°é™¤ä»¥num_envs
3. å‡å°è®­ç»ƒæ­¥é•¿ `1e7->5e6`
4. ä¿®å¤total_scoreå¿˜è®°åŠ æ­¥æ•°å¾—åˆ†çš„é—®é¢˜
5. æ—¥å¿—ä¸­åŠ å…¥bufferç›¸å…³å‚æ•° `miss_buffer`
6. `ent_coef: 1e-2 -> 1e-3`
7. ä¿®å¤å¥–åŠ±ä¸­delta treasureé”™è¯¯è®¡ç®—äº†ç¼ºå¤±çš„å®ç®±
8. `repeat_step_thre = 0.2 -> 0.4`
9. `n_treasure = [13,'norm',13,'norm'] -> ['norm', 13, 'norm']`
## 2024.8.14.
### v0.4.3
1. å°† `num_minibatches` æ›¿æ¢ä¸º `minibatch_size`, ç›´æŽ¥æŒ‡å®šminibatchå¤§å°
2. `update_epoches: 2 -> 1`
3. `norm_adv: True -> False`
4. `norm_sigma: 2.0 -> 3.0`, ä¿®æ­£ `action_space: np.arange(13) -> np.arange(14)`
5. ä¿®å¤envä¸­ `ratio` è®¡ç®—é”™è¯¯çš„é—®é¢˜, èƒ½å¤ŸæŒ‰æ¯”ä¾‹è°ƒæ•´å®ç®±æ•°ç›®, ä¿®å¤rewardé‡Œé¢å‘¨å›´æ­¥æ•°æƒ©ç½šçš„é”™è¯¯.
## 2024.8.15.
### v0.4.4
1. æ¯æ­¥éƒ½åŠ å…¥ `0.2` çš„æƒ©ç½š
2. `num_envs: 10 -> 12`
3. `num_steps: 128 -> 512`

### v0.4.4.1
è®­ç»ƒåˆ°47293æ­¥æ—¶, å‡ºçŽ°çŽ¯å¢ƒèŒƒå›´ä¸ºNoneçš„æŠ¥é”™, å¯¼è‡´è®­ç»ƒåœæ­¢???
```python
202024-08-15 13:54:04.110 | ERROR    | kaiwudrl.server.aisrv.kaiwu_rl_helper_standard:workflow:461 - aisrv kaiwu_rl_helper workflow() Exception 'NoneType' object has no attribute 'score', traceback.print_exc() is Traceback (most recent call last):
  File "/data/projects/back_to_the_realm/kaiwudrl/server/aisrv/kaiwu_rl_helper_standard.py", line 437, in workflow
    AlgoConf[CONFIG.algo].train_workflow([env], self.current_models, self.logger, self.monitor_proxy)
  File "/data/projects/back_to_the_realm/diy/train_workflow.py", line 45, in workflow
    next_obs, reward, terminations, truncations, infos = env.step(action)
                                                         ^^^^^^^^^^^^^^^^
  File "/data/projects/back_to_the_realm/diy/feature/definition.py", line 87, in step
    total_treasure_score = score.score
                           ^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'score'

# score æ¥æºäºŽ: frame_no, obs, score, terminated, truncated, _env_info = self.env.step(self.action)
```
åŠ å…¥å¯¹scoreçš„å¼‚å¸¸å¤„ç†, å¦‚æžœä¸ºNoneåˆ™åå¤è¿›è¡Œ `env.step`. å‡ºçŽ°è¯¥æŠ¥é”™çš„åŽŸå› å¯èƒ½æ˜¯ `num_steps` è°ƒåˆ°äº† `512` ? é‡æ–°å‡å°å›ž `128`
1. `num_steps: 512 -> 128`
2. `num_envs: 12 -> 10`
è®­ç»ƒåˆ°12hæ—¶å€™å†æ¬¡å‡ºçŽ°`score=None`çš„æƒ…å†µ (ç¡®è®¤åº”è¯¥å’Œç¡¬ç›˜ç©ºé—´ä¸è¶³æœ‰å…³), ä¸ºäº†èƒ½å¤Ÿä»Šå¤©è·‘å®Œè·‘æ¦œä»»åŠ¡, ç‰¹è®­ä¸€ä¸ª10ä¸ªå®ç®±çš„

## 2024.8.16.
æ— æ³•å¼€å¯åˆ°å®¢æˆ·ç«¯æŒ‡å®šçš„è¿›ç¨‹æ•°ç›®, åŽŸå› ä¹Ÿå¯èƒ½å’Œç¡¬ç›˜ç©ºé—´ä¸è¶³æœ‰å…³, å°½å¯èƒ½å¤šå¼€ä¸€ç‚¹, 16è¿›ç¨‹ä¸€èˆ¬åªèƒ½å¼€åˆ°12è¿›ç¨‹
1. `num_envs: 10 -> 12`
2. `each_step_punish: 0.2 -> 0.1`, åªåœ¨åŽåŠç¨‹è®­ç»ƒ `ratio > 0.5` ä¸­åŠ å…¥æ­¥æ•°æƒ©ç½š

## 2024.8.17.
### v1.0
å¯¹v0.4.3çš„4548æ­¥æ¨¡åž‹æŽ¥ç€è®­ç»ƒ:
1. é‡‡ç”¨æ¯æ­¥ `0.1` çš„æƒ©ç½š
2. `num_envs: 12 -> 10, num_steps: 128 -> 256`
3. åŠ å…¥éšæœºèµ·ç‚¹, åœ¨å‰50%çš„episodeä¸­æ™ºèƒ½ä½“åˆå§‹åŒ–åœ¨éšæœºçš„èµ·ç‚¹ä¸Š, åŽ50%åªèƒ½å‡ºçŽ°åœ¨2å·èŠ‚ç‚¹ä¸Š.
4. `learning_rate: 5e-5 -> 2.5e-5, ent_coef: 1e-3 -> 1e-4`

## 2024.8.19.
### v1.1
å®Œæˆv1.0è®­ç»ƒ, æå‡æŒºå¤§, éƒ¨åˆ†æƒ…å†µä¸‹ä¼šå‡ºçŽ°æ¼å®ç®±çš„é—®é¢˜
1. å…³é—­åŠ¨æ€å®ç®±å¥–åŠ±, å¢žå¤§å®ç®±å¥–åŠ±ä¸Žæƒ©ç½š `50 -> 100`
2. å¢žå¤§æ­¥æ•°æƒ©ç½š, `0.1 -> 0.2`
3. `n_treasure: norm -> uniform`
4. å…³é—­éšæœºèµ·ç‚¹ `random_start_position_ratio = 0.5 -> 0.0`
5. é™ä½Žå­¦ä¹ çŽ‡ `2.5e-5 -> 1e-5`
6. å¢žå¤§ `update_epochs: 1 -> 2`, 
7. å‡å° `ent_coef: 1e-4 -> 1e-5`

æ²¡å†…å­˜äº†ðŸ˜¢, ä¸èƒ½å¢žå¤§ `replay_buffer_capacity: 100 -> 200, train_batch_size: 30 -> 60`
